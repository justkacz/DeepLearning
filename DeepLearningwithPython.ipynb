{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30bb8ac",
   "metadata": {},
   "source": [
    "TENSOR = multidimensional numpy array\n",
    "\n",
    "- 0D TENSOR = SCALAR, TENSOR that contains only ONE number -> ndim=0\n",
    "    \n",
    "    e.g. np.array(14)\n",
    "\n",
    "\n",
    "    RANK => the NUMBER of AXES (=DIMENSIONS) of a tensor\n",
    "    \n",
    "    Shape—This is a tuple of integers that describes how many dimensions the tensor has along each axis e.g. 3D tensor example     has shape (3, 3, 5). A vector has a shape with a single element, such as (5,), whereas a scalar has an empty shape, ()\n",
    "\n",
    "- 1D TENSOR = VECTOR, an array of numbers ndim=1\n",
    "\n",
    "    e.g. np.array([4,14,2,13,5,9])\n",
    "    \n",
    "- 2D TENSOR = MATRIX, 2 axes =. ROWS & COLUMNS\n",
    "\n",
    "- 3D TENSOR - matrices packed in new array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1498b575",
   "metadata": {},
   "source": [
    "TENSOR OPERATIONS:\n",
    "\n",
    "1) ELEMENT WISE OPERATIONS (relu()->max())\n",
    "2) BROADCASTING => tensors with different shapes:\n",
    "\n",
    "- Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
    "- The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor.\n",
    "\n",
    "3) DOT:\n",
    "\n",
    "a = np.array([[1,2],[3,4]]) \n",
    "\n",
    "b = np.array([[11,12],[13,14]]) \n",
    "\n",
    "[[1 * 11+2 * 13, 1 * 12+2 * 14],[3 * 11+4 * 13, 3 * 12+4 * 14]]\n",
    "\n",
    "4) RESHAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7ef5e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=np.arange(12).reshape(3,4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42b4528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf72d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70059093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(train_labels) # labels are digits from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "406bd1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# 1) NETWORK:\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))  # first layer\n",
    "network.add(layers.Dense(10, activation='softmax'))   # second and the last layer, \n",
    "# 10 => it will return an array of 10 probability scores, each score will be the probability that the current digit \n",
    "# image belongs to one of our 10 digit classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95394338",
   "metadata": {},
   "source": [
    "2) COMPILATION:\n",
    "\n",
    "* A loss function—How the network will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction; it implements a specific variant of stochastic gradient descent (SGD)\n",
    "\n",
    "* An optimizer—The mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "\n",
    "* Metrics to monitor during training and testing—Here, we’ll only care about accuracy (the fraction of the images that were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "360b137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation:\n",
    "network.compile(optimizer='rmsprop',  # loss function\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87d60e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Preparing the image data => reshaping to (6000, 28*28) and scaling ( from 0 to 1):\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b59e44ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5225980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Preparing the labels - categorically encoding:\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels=to_categorical(train_labels)\n",
    "test_labels=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eced59bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 5s 9ms/step - loss: 0.2552 - accuracy: 0.9259\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.1052 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0691 - accuracy: 0.9789\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0502 - accuracy: 0.9850\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.0387 - accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d612fe0790>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training network:\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be69a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0706 - accuracy: 0.9792\n",
      "Test accuracy:  0.979200005531311\n"
     ]
    }
   ],
   "source": [
    "# testing:\n",
    "loss, accuracy=network.evaluate(test_images, test_labels)\n",
    "print('Test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929314a4",
   "metadata": {},
   "source": [
    "gap between training accuracy and test accuracy: training 0.9888 test: 0.9792 = OVERFITTING:\n",
    "machine-learning models tend to perform worse on new data than on their training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46f98b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = (60000, 28, 28) and data type = uint8\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(f'Shape = {train_images.shape} and data type = {train_images.dtype}')\n",
    "# 60000 matrices of 28x8 integers (each such matrix is a greyscale image with coefficients between 0-255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6275c7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1db111e7700>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "number=test_images[4]\n",
    "plt.imshow(number, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67880264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeseries -> 3D tensor (samples, features, timesteps)\n",
    "# picture -> 3D tensor (heigh, width, color -> 1 if grey, 3 color), 4D if batch (btach_size, heigh, width, color)\n",
    "# video -> 4D tensor, a sequence of frames, each frame being a color image (frames, height, width, color), 5D if batch  \n",
    "#           (samples, frames, height, width, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa256d9c",
   "metadata": {},
   "source": [
    "GRADIENT BASED OPTIMIZATION:\n",
    "\n",
    "DERIVATIVE -> The SLOPE 'a' is called the derivative of 'f' in a certain point 'p'. If 'a' is negative, it means a small change\n",
    "of 'x' around 'p' will result in a decrease of f(x) and if a is positive, a small change in x will result in an increase of f(x). Further, the absolute value of a (the magnitude of the derivative) tells how quickly this increase or decrease\n",
    "will happen.\n",
    "\n",
    "\n",
    "GRADIENT -> is the derivative of a tensor operation; to decrease loss, the weights should be updated in the opposite direction from the gradient\n",
    "\n",
    "CHAINS -> A neural network function consists of many tensor operations chained together, each of which has a simple, known derivative. Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers applying the chain rule to compute the contribution that each parameter had in the loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two ways to define a model: using the Sequential class (only for linear stacks of layers, which is the most common \n",
    "# network architecture by far) or the functional API\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # input shape will adjust automatically based on previous layer.\n",
    "\n",
    "# compilation step (configuration):\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='mse', metrics=['accuracy'])\n",
    "model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
